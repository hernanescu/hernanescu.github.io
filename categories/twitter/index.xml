<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Twitter on #atR://Hernán Escudero</title>
    <link>/categories/twitter/</link>
    <description>Recent content in Twitter on #atR://Hernán Escudero</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es-es</language>
    <lastBuildDate>Fri, 07 Dec 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/twitter/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>La máquina de scrapear: Twitter</title>
      <link>/2018/12/maquina-scrapear/</link>
      <pubDate>Fri, 07 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/12/maquina-scrapear/</guid>
      <description>Una de las cosas más fascinantes de esta clase de herramientas es usarlas para organizar información que existe de manera “pública” (ya veremos por qué las comillas). Usando internet y las redes sociales dejamos un auténtico reguero de información que de tan abundante y compleja que es, resulta por momentos inabordable.
Al empezar a estudiar R y lo que es big data, lo primero que pensé es que sería interesante (y por qué no, divertido) poder usar esta herramienta para relevar información de Twitter, la red social de opinión por excelencia.</description>
    </item>
    
  </channel>
</rss>